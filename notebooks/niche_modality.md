# mRNA niche data generation

We generate mRNA niche data by weighted average expression of RNA expression. Functions are adapted based on the SEDR package (https://github.com/JinmiaoChenLab/SEDR/).
`adata_h5` is the h5ad file that stores RNA expression. 

```python
import networkx as nx
import numpy as np
import torch
import scipy.sparse as sp
from scipy.spatial import distance

def preprocess_graph(adj):
    adj = sp.coo_matrix(adj)
    adj_ = adj + sp.eye(adj.shape[0])
    rowsum = np.array(adj_.sum(1))
    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())
    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()
    return adj_normalized, sparse_mx_to_torch_sparse_tensor(adj_normalized)

def edgeList2edgeDict(edgeList, nodesize):
    graphdict = {}
    tdict = {}
    for edge in edgeList:
        end1 = edge[0]
        end2 = edge[1]
        tdict[end1] = ""
        tdict[end2] = ""
        if end1 in graphdict:
            tmplist = graphdict[end1]
        else:
            tmplist = []
        tmplist.append(end2)
        graphdict[end1] = tmplist

    # check and get full matrix
    for i in range(nodesize):
        if i not in tdict:
            graphdict[i] = []

    return graphdict

def graph_computing(adj_coo, cell_num, params):
    edgeList = []
    for node_idx in range(cell_num):
        tmp = adj_coo[node_idx, :].reshape(1, -1)
        distMat = distance.cdist(tmp, adj_coo, params.knn_distanceType)
        res = distMat.argsort()[:params.k + 1]
        tmpdist = distMat[0, res[0][1:params.k + 1]]
        boundary = np.mean(tmpdist) + np.std(tmpdist)
        for j in np.arange(1, params.k + 1):
            if distMat[0, res[0][j]] <= boundary:
                weight = 1.0
            else:
                weight = 0.0
            edgeList.append((node_idx, res[0][j], weight))

    return edgeList

def graph_construction(adj_coo, cell_N, params):
    adata_Adj = graph_computing(adj_coo, cell_N, params)
    graphdict = edgeList2edgeDict(adata_Adj, cell_N)
    adj_org = nx.adjacency_matrix(nx.from_dict_of_lists(graphdict))

    # Store original adjacency matrix (without diagonal entries) for later
    adj_m1 = adj_org
    adj_m1 = adj_m1 - sp.dia_matrix((adj_m1.diagonal()[np.newaxis, :], [0]), shape=adj_m1.shape)
    adj_m1.eliminate_zeros()

    # Some preprocessing
    adj_norm_write, adj_norm_m1 = preprocess_graph(adj_m1)
    adj_label_m1 = adj_m1 + sp.eye(adj_m1.shape[0])
    adj_label_m1 = torch.FloatTensor(adj_label_m1.toarray())
    norm_m1 = adj_m1.shape[0] * adj_m1.shape[0] / float((adj_m1.shape[0] * adj_m1.shape[0] - adj_m1.sum()) * 2)

    graph_dict = {
        "adj_org": adj_org,
        "adj_norm": adj_norm_m1,
        "adj_label": adj_label_m1,
        "norm_value": norm_m1
    }
    # mask is binary matrix for semi-supervised/multi-dataset (1-valid edge, 0-unknown edge)
    if params.using_mask is True:
        graph_dict["adj_mask"] = torch.ones(cell_N, cell_N)
    return graph_dict, adj_norm_write


graph_dict, adj_norm_write = graph_construction(adata_h5.obsm['spatial'], adata_h5.shape[0], params)

### save niche_mrna
adj_label = graph_dict['adj_label'].cpu().detach().numpy()
spatial_coo=adata_h5.obsm['spatial']
niche_mrna=np.zeros(adata_h5.X.shape)
for ind,i in enumerate(adj_label):
    distMat = distance.cdist(spatial_coo[ind,:].reshape(1,-1), spatial_coo[i.astype(bool),:], metric='euclidean')
    distMat[distMat>0]=1/distMat[distMat>0]
    distMat_normed = distMat / sum(sum(distMat))
    niche_mrna[ind, :] = distMat_normed.dot(adata_h5.X[i.astype(bool), :])
### save niche_mrna
mrna=pd.DataFrame(niche_mrna.T,index=adata_h5.var_names,columns=adata_h5.obs_names)
mrna.to_csv('./niche_mrna.csv')

```

For DLPFC data, we use 100 PCs in `data_.obsm['X_pca']` generated by stLearn package (https://stlearn.readthedocs.io/en/latest/) as input.
```
from sklearn.cluster import KMeans
st.spatial.SME.SME_normalize(data, use_data="raw", weights="physical_distance")
data_ = data.copy()
data_.X = data_.obsm['raw_SME_normalized']
st.pp.scale(data_)
st.em.run_pca(data_,n_comps=100)
```



